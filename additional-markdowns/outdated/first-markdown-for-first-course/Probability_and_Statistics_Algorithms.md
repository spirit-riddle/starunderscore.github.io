# Probability and Statistics Algorithms

## Data Sampling
1. **Random Sampling**  
   - **Purpose**: Selects a subset of data points randomly from a larger dataset.  
   - **Application**: Survey data analysis and randomized experiments.

2. **Stratified Sampling**  
   - **Purpose**: Divides the population into strata and samples proportionally from each group.  
   - **Application**: Opinion polling and clinical trials.

3. **Monte Carlo Simulation**  
   - **Purpose**: Uses random sampling to model probabilistic systems and estimate numerical results.  
   - **Application**: Risk analysis in finance and operations research.

4. **Bootstrapping**  
   - **Purpose**: Resamples a dataset with replacement to estimate the sampling distribution of a statistic.  
   - **Application**: Confidence interval estimation and hypothesis testing.

---

## Inference
1. **Maximum Likelihood Estimation (MLE)**  
   - **Purpose**: Estimates parameters of a probability distribution by maximizing the likelihood function.  
   - **Application**: Parameter estimation in logistic regression and time-series analysis.

2. **Bayesian Inference**  
   - **Purpose**: Updates probabilities based on new evidence using Bayes' theorem.  
   - **Application**: Spam filtering and medical diagnosis.

3. **Expectation-Maximization (EM) Algorithm**  
   - **Purpose**: Estimates parameters in probabilistic models with latent variables iteratively.  
   - **Application**: Clustering in machine learning and image segmentation.

4. **Markov Chain Monte Carlo (MCMC)**  
   - **Purpose**: Generates samples from complex probability distributions.  
   - **Application**: Bayesian model estimation and computational biology.

---

## Bayesian Methods
1. **Bayes' Theorem**  
   - **Purpose**: Calculates posterior probabilities by incorporating prior beliefs and evidence.  
   - **Application**: Fraud detection and predictive modeling.

2. **Naive Bayes Classifier**  
   - **Purpose**: Applies Bayes' theorem for classification assuming feature independence.  
   - **Application**: Text classification and sentiment analysis.

3. **Gaussian Mixture Models (GMM)**  
   - **Purpose**: Models data as a mixture of multiple Gaussian distributions.  
   - **Application**: Clustering and density estimation.

4. **Kalman Filter**  
   - **Purpose**: Combines Bayesian inference with state-space modeling to estimate dynamic system states.  
   - **Application**: Navigation systems and robotics.

---

## Hypothesis Testing
1. **Chi-Square Test**  
   - **Purpose**: Tests the independence of two categorical variables.  
   - **Application**: Market research and genetics.

2. **T-Test**  
   - **Purpose**: Compares the means of two groups to determine if they are statistically different.  
   - **Application**: A/B testing in marketing and product design.

3. **ANOVA (Analysis of Variance)**  
   - **Purpose**: Tests whether the means of multiple groups are significantly different.  
   - **Application**: Clinical trials and agricultural studies.

4. **Z-Test**  
   - **Purpose**: Tests the means of two populations when sample sizes are large.  
   - **Application**: Quality control and financial analysis.

---

## Regression and Forecasting
1. **Linear Regression**  
   - **Purpose**: Models the relationship between a dependent variable and one or more independent variables.  
   - **Application**: Predictive analytics in finance and marketing.

2. **Logistic Regression**  
   - **Purpose**: Models probabilities for binary classification problems.  
   - **Application**: Credit scoring and disease prediction.

3. **Time-Series Analysis (ARIMA)**  
   - **Purpose**: Models and forecasts time-dependent data using autoregression and moving averages.  
   - **Application**: Stock price prediction and weather forecasting.

4. **Hidden Markov Models (HMM)**  
   - **Purpose**: Models systems that transition between hidden states over time.  
   - **Application**: Speech recognition and bioinformatics.

---

## Special Applications
1. **Principal Component Analysis (PCA)**  
   - **Purpose**: Reduces dimensionality while retaining variance by transforming to principal components.  
   - **Application**: Exploratory data analysis and feature engineering.

2. **Bayesian Network**  
   - **Purpose**: Represents probabilistic dependencies among a set of variables.  
   - **Application**: Decision support systems and gene regulatory networks.

3. **K-Means Clustering**  
   - **Purpose**: Groups data points into k clusters by minimizing variance within each cluster.  
   - **Application**: Customer segmentation and pattern recognition.

4. **Jackknife Resampling**  
   - **Purpose**: Estimates the bias and variance of a statistical estimator.  
   - **Application**: Error estimation in machine learning models.

---

Let me know if you'd like this as a markdown file for download!
